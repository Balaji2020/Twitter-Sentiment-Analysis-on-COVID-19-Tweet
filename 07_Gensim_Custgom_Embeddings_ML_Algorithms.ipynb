{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srmetlakunta\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tqdm\\std.py:648: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "random.seed(10)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import gensim\n",
    "from gensim.models import FastText\n",
    "from gensim.models.word2vec import Word2Vec # the word2vec model gensim class\n",
    "LabeledSentence = gensim.models.doc2vec.LabeledSentence \n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer # a tweet tokenizer from nltk.\n",
    "tokenizer = TweetTokenizer()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score,precision_recall_fscore_support, classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_date</th>\n",
       "      <th>Tweet_time</th>\n",
       "      <th>Tweet_City</th>\n",
       "      <th>Tweet_Country</th>\n",
       "      <th>Tweet_account</th>\n",
       "      <th>Retweet_count</th>\n",
       "      <th>Tweet_Text</th>\n",
       "      <th>Created Date</th>\n",
       "      <th>tweet_without_stopwords</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>vader_polarity</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4/1/2020</td>\n",
       "      <td>0:08:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Australia</td>\n",
       "      <td>GSK_AU</td>\n",
       "      <td>0</td>\n",
       "      <td>ask award research excellence open nomination ...</td>\n",
       "      <td>2020-04-01 00:08:00</td>\n",
       "      <td>ask award research excellence open nomination ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.9349</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4/1/2020</td>\n",
       "      <td>0:35:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Australia</td>\n",
       "      <td>GSK_AU</td>\n",
       "      <td>3</td>\n",
       "      <td>award research excellence open nomination awar...</td>\n",
       "      <td>2020-04-01 00:35:00</td>\n",
       "      <td>award research excellence open nomination awar...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.9022</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Tweet_date Tweet_time Tweet_City Tweet_Country Tweet_account  Retweet_count  \\\n",
       "0   4/1/2020    0:08:00        NaN     Australia        GSK_AU              0   \n",
       "1   4/1/2020    0:35:00        NaN     Australia        GSK_AU              3   \n",
       "\n",
       "                                          Tweet_Text         Created Date  \\\n",
       "0  ask award research excellence open nomination ...  2020-04-01 00:08:00   \n",
       "1  award research excellence open nomination awar...  2020-04-01 00:35:00   \n",
       "\n",
       "                             tweet_without_stopwords  neg    neu    pos  \\\n",
       "0  ask award research excellence open nomination ...  0.0  0.297  0.703   \n",
       "1  award research excellence open nomination awar...  0.0  0.419  0.581   \n",
       "\n",
       "   vader_polarity sentiment  \n",
       "0          0.9349  positive  \n",
       "1          0.9022  positive  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/sentiment_twitter_data.csv\")\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['tweet_without_stopwords']\n",
    "y = data['sentiment'].apply({'positive':2,'negative':0,'neutral':1}.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress-bar: 100%|███████████████████████████████████████████████████████████| 13724/13724 [00:00<00:00, 17520.01it/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize(tweet):\n",
    "    try:\n",
    "        tokens = tokenizer.tokenize(tweet)\n",
    "        return tokens\n",
    "    except:\n",
    "        return 'NC'\n",
    "\n",
    "def postprocess(data, n=300):\n",
    "    data['tokens'] = data['Tweet_Text'].progress_map(tokenize)  ## progress_map is a variant of the map function plus a progress bar. Handy to monitor DataFrame creations.\n",
    "    # data = data[data.tokens != 'NC']\n",
    "    data.reset_index(inplace=True)\n",
    "    data.drop('index', inplace=True, axis=1)\n",
    "    return data\n",
    "\n",
    "tokenData = postprocess(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Gensim fasttext custom embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 13724/13724 [00:00<00:00, 756984.67it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 13724/13724 [00:00<00:00, 489103.82it/s]\n"
     ]
    }
   ],
   "source": [
    "f2vec = FastText(size=300, window=5, min_count=3, workers=4,sg=1)\n",
    "f2vec.build_vocab([x for x in tqdm(data['tokens'])])\n",
    "f2vec.train([x for x in tqdm(data['tokens'])],total_examples=f2vec.corpus_count,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of word vectors: 4444\n"
     ]
    }
   ],
   "source": [
    "x_vectors = f2vec.wv\n",
    "print(\"Number of word vectors: {}\".format(len(x_vectors.vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10979,), (10979,), (2745,), (2745,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x, test_x, train_y,test_y = train_test_split(data['Tweet_Text'], y, test_size=0.2, random_state=1)\n",
    "train_x.shape, train_y.shape, test_x.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sum up the each sentence to 300d vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srmetlakunta\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  import sys\n",
      "C:\\Users\\srmetlakunta\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "x_values = np.zeros((1, 300))\n",
    "train_x_lst = []\n",
    "test_x_lst = []\n",
    "for val in range(len(train_x)):\n",
    "    x_values = np.zeros((1, 300))\n",
    "    for tok in data['tokens'][val]:\n",
    "        x_values = x_values + f2vec[tok]\n",
    "    train_x_lst.append(x_values)\n",
    "    \n",
    "for val in range(len(test_x)):\n",
    "    x_values = np.zeros((1, 300))\n",
    "    for tok in data['tokens'][val]:\n",
    "        x_values = x_values + f2vec[tok]\n",
    "    test_x_lst.append(x_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_x = np.reshape(train_x_lst, (10979*1, 300))\n",
    "new_test_x = np.reshape(test_x_lst, (2745*1, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10979, 2745, 10979, 2745)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_x_lst), len(test_x_lst), len(new_train_x), len(new_test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest train accuracy\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.77      0.81      3168\n",
      "     neutral       0.79      0.85      0.82      4113\n",
      "    positive       0.81      0.81      0.81      3698\n",
      "\n",
      "    accuracy                           0.81     10979\n",
      "   macro avg       0.82      0.81      0.81     10979\n",
      "weighted avg       0.81      0.81      0.81     10979\n",
      "\n",
      "***************\n",
      "random forest test accuracy\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.28      0.27      0.27       775\n",
      "     neutral       0.37      0.38      0.37      1012\n",
      "    positive       0.35      0.34      0.35       958\n",
      "\n",
      "    accuracy                           0.34      2745\n",
      "   macro avg       0.33      0.33      0.33      2745\n",
      "weighted avg       0.34      0.34      0.34      2745\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 20, criterion = 'entropy',random_state = 42)\n",
    "rf.fit(new_train_x, train_y)\n",
    "\n",
    "\n",
    "rf_pred_train = rf.predict(new_train_x)\n",
    "print('random forest train accuracy')\n",
    "print(classification_report(train_y, rf_pred_train, target_names=['negative','neutral', 'positive']))\n",
    "\n",
    "print('***************')\n",
    "rf_pred_test = rf.predict(new_test_x)\n",
    "print('random forest test accuracy')\n",
    "print(classification_report(test_y, rf_pred_test, target_names=['negative','neutral', 'positive']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB().fit(new_train_x, train_y)\n",
    "\n",
    "nb_pred_test = nb.predict(new_test_x)\n",
    "nb_pred_train = nb.predict(new_train_x)\n",
    "print('Naive Bayes train accuracy')\n",
    "print(classification_report(train_y, nb_pred_train, target_names=['negative','neutral', 'positive']))\n",
    "\n",
    "print('***************')\n",
    "\n",
    "print('Naive Bayes test accuracy')\n",
    "print(classification_report(test_y, nb_pred_test, target_names=['negative','neutral', 'positive']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=5,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best')\n",
      "Decision Tree train accuracy\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.80      0.80      3168\n",
      "     neutral       0.79      0.86      0.82      4113\n",
      "    positive       0.84      0.76      0.80      3698\n",
      "\n",
      "    accuracy                           0.81     10979\n",
      "   macro avg       0.81      0.80      0.81     10979\n",
      "weighted avg       0.81      0.81      0.81     10979\n",
      "\n",
      "***************\n",
      "Decision Tree test accuracy\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.27      0.29      0.28       775\n",
      "     neutral       0.37      0.37      0.37      1012\n",
      "    positive       0.35      0.32      0.33       958\n",
      "\n",
      "    accuracy                           0.33      2745\n",
      "   macro avg       0.33      0.33      0.33      2745\n",
      "weighted avg       0.33      0.33      0.33      2745\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(criterion='gini',max_depth=None, min_samples_split=5, min_samples_leaf=1,\n",
    "                            min_weight_fraction_leaf=0.0)\n",
    "print(dt)\n",
    "dt = dt.fit(new_train_x, train_y)\n",
    "\n",
    "dttrain = dt.predict(new_train_x)\n",
    "print('Decision Tree train accuracy')\n",
    "print(classification_report(train_y, dttrain, target_names=['negative','neutral', 'positive']))\n",
    "\n",
    "print('***************')\n",
    "dttest = dt.predict(new_test_x)\n",
    "print('Decision Tree test accuracy')\n",
    "print(classification_report(test_y, dttest, target_names=['negative','neutral', 'positive']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid = [{'kernel': ['rbf'], 'gamma': [1e-3],  'C': [1, 10]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srmetlakunta\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid=[{'C': [1, 10], 'gamma': [0.001], 'kernel': ['rbf']}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model = GridSearchCV(SVC(), params_grid)\n",
    "svm_model.fit(new_train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for training data: 0.36323891064759994 \n",
      "\n",
      "Best C: 1 \n",
      "\n",
      "Best Kernel: rbf \n",
      "\n",
      "Best Gamma: 0.001 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View the accuracy score\n",
    "print('Best score for training data:', svm_model.best_score_,\"\\n\") \n",
    "# View the best parameters for the model found using grid search\n",
    "print('Best C:',svm_model.best_estimator_.C,\"\\n\") \n",
    "print('Best Kernel:',svm_model.best_estimator_.kernel,\"\\n\")\n",
    "print('Best Gamma:',svm_model.best_estimator_.gamma,\"\\n\")\n",
    "\n",
    "final_model = svm_model.best_estimator_\n",
    "Y_pred = final_model.predict(new_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest train accuracy\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      0.16      0.25      3168\n",
      "     neutral       0.44      0.86      0.58      4113\n",
      "    positive       0.56      0.33      0.42      3698\n",
      "\n",
      "    accuracy                           0.48     10979\n",
      "   macro avg       0.55      0.45      0.42     10979\n",
      "weighted avg       0.54      0.48      0.43     10979\n",
      "\n",
      "***************\n",
      "Decision Tree test accuracy\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.24      0.04      0.07       775\n",
      "     neutral       0.37      0.79      0.50      1012\n",
      "    positive       0.36      0.17      0.23       958\n",
      "\n",
      "    accuracy                           0.36      2745\n",
      "   macro avg       0.32      0.33      0.27      2745\n",
      "weighted avg       0.33      0.36      0.28      2745\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svmtrain = final_model.predict(new_train_x)\n",
    "print('SVM train accuracy')\n",
    "print(classification_report(train_y, svmtrain, target_names=['negative','neutral', 'positive']))\n",
    "\n",
    "print('***************')\n",
    "svmtest = final_model.predict(new_test_x)\n",
    "print('SVM test accuracy')\n",
    "print(classification_report(test_y, svmtest, target_names=['negative','neutral', 'positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install chart_studio        #Install chart_studio for plotly plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chart_studio.plotly as py                            #Import chart_studio for various plotly plot\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.offline import iplot\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'colab'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot shows the Comparison of Different ML Classification model for Evaluation metrics of Negative sentiment label\n",
    "trace1 = {\n",
    "  \"name\": \"Accuracy\", \n",
    "  \"type\": \"bar\", \n",
    "  \"x\": [\"Random Forest\", \"Decision Tree\", \"SVM_rgf\"], \n",
    "  \"y\": [81,81,48]\n",
    "}\n",
    "\n",
    "trace2 = {\n",
    "  \"name\": \"Precision\", \n",
    "  \"type\": \"bar\", \n",
    "  \"x\": [\"Random Forest\", \"Decision Tree\", \"SVM_rgf\"], \n",
    "  \"y\": [85,80,66]\n",
    "}\n",
    "\n",
    "trace3 = {\n",
    "  \"name\": \"Recall\", \n",
    "  \"type\": \"bar\", \n",
    "  \"x\": [\"Random Forest\", \"Decision Tree\", \"SVM_rgf\"], \n",
    "  \"y\": [77,82,16]\n",
    "}\n",
    "\n",
    "trace4 = {\n",
    "  \"name\": \"F1-score\", \n",
    "  \"type\": \"bar\", \n",
    "  \"x\": [\"Random Forest\", \"Decision Tree\", \"SVM_rgf\"], \n",
    "  \"y\": [81,81,25]\n",
    "}\n",
    "\n",
    "data = [trace1,trace2,trace3,trace4]\n",
    "layout = go.Layout(barmode = \"group\",title= 'ML Model Evaluation Metrics Comparision on Negative Tweet sentiment ')\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot shows the Comparison of Different ML Classification model for Evaluation metrics of Neutral sentiment label\n",
    "trace1 = {\n",
    "  \"name\": \"Accuracy\", \n",
    "  \"type\": \"bar\", \n",
    "  \"x\": [\"Random Forest\", \"Decision Tree\", \"SVM_rgf\"], \n",
    "  \"y\": [81,81,48]\n",
    "}\n",
    "\n",
    "trace2 = {\n",
    "  \"name\": \"Precision\", \n",
    "  \"type\": \"bar\", \n",
    "  \"x\": [\"Random Forest\", \"Decision Tree\", \"SVM_rgf\"], \n",
    "  \"y\": [79,79,44]\n",
    "}\n",
    "\n",
    "trace3 = {\n",
    "  \"name\": \"Recall\", \n",
    "  \"type\": \"bar\", \n",
    "  \"x\": [\"Random Forest\", \"Decision Tree\", \"SVM_rgf\"], \n",
    "  \"y\": [85,86,86]\n",
    "}\n",
    "\n",
    "trace4 = {\n",
    "  \"name\": \"F1-score\", \n",
    "  \"type\": \"bar\", \n",
    "  \"x\": [\"Random Forest\", \"Decision Tree\", \"SVM_rgf\"], \n",
    "  \"y\": [82,82,58]\n",
    "}\n",
    "\n",
    "data = [trace1,trace2,trace3,trace4]\n",
    "layout = go.Layout(barmode = \"group\",title= 'ML Model Evaluation Metrics Comparision on Neutral Tweet sentiment ')\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot shows the Comparison of Different ML Classification model for Evaluation metrics of Positive sentiment label\n",
    "trace1 = {\n",
    "  \"name\": \"Accuracy\", \n",
    "  \"type\": \"bar\", \n",
    "  \"x\": [\"Random Forest\", \"Decision Tree\", \"SVM_rgf\"], \n",
    "  \"y\": [81,81,48]\n",
    "}\n",
    "\n",
    "trace2 = {\n",
    "  \"name\": \"Precision\", \n",
    "  \"type\": \"bar\", \n",
    "  \"x\": [\"Random Forest\", \"Decision Tree\", \"SVM_rgf\"], \n",
    "  \"y\": [81,86,56]\n",
    "}\n",
    "\n",
    "trace3 = {\n",
    "  \"name\": \"Recall\", \n",
    "  \"type\": \"bar\", \n",
    "  \"x\": [\"Random Forest\", \"Decision Tree\", \"SVM_rgf\"], \n",
    "  \"y\": [81,76,33]\n",
    "}\n",
    "\n",
    "trace4 = {\n",
    "  \"name\": \"F1-score\", \n",
    "  \"type\": \"bar\", \n",
    "  \"x\": [\"Random Forest\", \"Decision Tree\", \"SVM_rgf\"], \n",
    "  \"y\": [81,80,42]\n",
    "}\n",
    "\n",
    "data = [trace1,trace2,trace3,trace4]\n",
    "layout = go.Layout(barmode = \"group\",title= 'ML Model Evaluation Metrics Comparision on Positive Tweet sentiment ')\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
